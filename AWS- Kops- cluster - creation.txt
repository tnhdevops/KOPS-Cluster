Deploying a production ready Cluster
====================================
Google - gcloud container
AWS - eksctl create cluster
Azure - az aks create 
Oracle - oci ce cluster create 

https://kubespray.io/#/

KOPS - Kubernetes Opeartions

This automates cluster with production standard. 
 - Automatic node provisioning
 - SG , NAT , VPC , IG , Subnet , Route 53
 - Autoscaling , HA

Prerequisits AWS
---------------

 - Admin Instance
 - IAM role
 - Domain name and hosted Zone - for k9's API server
 - S3 Bucket - to store the configuration and state info / not for etcd
 
https://kops.sigs.k8s.io/
https://kubernetes.io/docs/setup/production-environment/tools/kops/


Step 1
======

create AWS security group with following  ports

Type	         Protocol      Port Range     Source
----             --------      ----------     ------	
HTTP              TCP           80           0.0.0.0/0
Custom TCP Rule   TCP           8080         0.0.0.0/0
SSH               TCP           22           0.0.0.0/0
HTTPS             TCP           443          0.0.0.0/0




Step 2
======
Create a Free tier Ubuntu Instance , select the above  security group while creating.


  connect using mobaxterm 

  ubuntu@ip-172-31-39-31:~$sudo su - 

  and switch to root user

Step 3
======

Install AWsCLi

check Phython has been installed
--------------------------------

root@ip-172-31-39-31:~# python3
Python 3.8.2 (default, Jul 16 2020, 14:00:26)
[GCC 9.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.

press  Ctrl-D  to exit

install unzip utility
---------------------

root@ip-172-31-39-31:~#apt-get install unzip
Reading package lists... Done
Building dependency tree
Reading state information... Done
Suggested packages:
  zip
The following NEW packages will be installed:
  unzip
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.
Need to get 169 kB of archives.
After this operation, 593 kB of additional disk space will be used.
Get:1 http://us-east-2.ec2.archive.ubuntu.com/ubuntu focal/main amd64 unzip amd64 6.0-25ubuntu1 [169 kB]
Fetched 169 kB in 0s (1381 kB/s)
Selecting previously unselected package unzip.
(Reading database ... 59670 files and directories currently installed.)
Preparing to unpack .../unzip_6.0-25ubuntu1_amd64.deb ...
Unpacking unzip (6.0-25ubuntu1) ...
Setting up unzip (6.0-25ubuntu1) ...
Processing triggers for mime-support (3.64ubuntu1) ...
Processing triggers for man-db (2.9.1-1) ...

download AWSCli utility
-----------------------

root@ip-172-31-39-31:~# curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 32.2M  100 32.2M    0     0  35.0M      0 --:--:-- --:--:-- --:--:-- 34.9M


root@ip-172-31-39-31:~# unzip awscliv2.zip

root@ip-172-31-39-31:~# ./aws/install
You can now run: /usr/local/bin/aws --version

once the installation finished check for AWSCli functionality


root@ip-172-31-39-31:~# aws
usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]
To see help text, you can run:

  aws help
  aws <command> help
  aws <command> <subcommand> help
aws: error: the following arguments are required: command

Step 4
======

Install Kubectl , Change the permission and move to /usr/local/bin

root@ip-172-31-39-31:~# 
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 41.0M  100 41.0M    0     0  3065k      0  0:00:13  0:00:13 --:--:-- 3093k
root@ip-172-31-39-31:~#  chmod +x ./kubectl
root@ip-172-31-39-31:~#  sudo mv ./kubectl /usr/local/bin/kubectl


Step 5
======

Create an IAM role with Route53, EC2, IAM and S3 full access


go to IAM , Select Roles , Click Create , Select AWS Service as the 
Type of trusted entity ,

Click EC2 as common use cases
Click next : permissions

serch for S3Fullaccess,EC2FullAccess,Route53FullAccess and 
IAMFullAccess

and select the check box for each

next Add a Tag

Next - Review

give a role name

and create.

Attach this Role to ubuntu Instance 

 select the ubumtu instance , Actions , Security, Modify IAM Role , Select the role and apply.
 
Step 6
======

Check whether S3 is accessible


root@ip-172-31-39-31:~# aws s3 ls

 u will see no buckets here

Step 7
======

Configure the AWS  Cli

root@ip-172-31-39-31:~#  aws configure
AWS Access Key ID [None]:
AWS Secret Access Key [None]:
Default region name [None]: ap-southeast-1
Default output format [None]:

please note the only input u have to give is ur  Region where ur Ubuntu Instance is running

above we are using the ap-southeast-1 Region 

Step 8
======

Install kops on ubuntu instance

root@ip-172-31-39-31:~#curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   640  100   640    0     0  11851      0 --:--:-- --:--:-- --:--:-- 11851
100 93.9M  100 93.9M    0     0  16.4M      0  0:00:05  0:00:05 --:--:-- 17.0M
root@ip-172-31-39-31:~#  chmod +x kops-linux-amd64
root@ip-172-31-39-31:~#  sudo mv kops-linux-amd64 /usr/local/bin/kops

KOPS - Kuberbetes Operations - this utility allows cluster configuration on AWS

Step 9
======

Create a Route53 private hosted zone (you can create Public hosted zone if you have a domain)

select Route53 on AWS Console

under DNS Management Click create hosted zone

give a Domain name - tnhdevops.lk

select private hosted zone  

select the region where the instance is -  us-east-2

 and the default VPC 

  and create it.

Step 10
=======
create an S3 bucket

root@ip-172-31-39-31:~# aws s3 mb s3://dev.k8s.tnhdevops.lk
make_bucket: dev.k8s.Devops.lk

mb - make bucket

go to S3 and verify

Expose the bucket

root@ip-172-31-39-31:~# export KOPS_STATE_STORE=s3://dev.k8s.tnhdevops.lk

Step 11
=======

Create sshkeys before creating cluster

root@ip-172-31-19-141:~# ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa
Your public key has been saved in /root/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:Mr/S7LWIhNV9e9RdF8n3PHJP/mL05u85eDEG43odQRE root@ip-172-31-19-141
The key's randomart image is:
+---[RSA 3072]----+
|              .E+|
|               +o|
|              ..=|
|       . .   + =B|
|      + S . o *o*|
|     o +   . +.=o|
|    . .o. . o.=.=|
|     ...o+ o +o+=|
|      .o+ . ...**|
+----[SHA256]-----+

Step 12
=======

Create Kubernetes cluster definition and store it on S3 bucket

kops create cluster \
--state=${KOPS_STATE_STORE} \
--node-count=2 \
--master-size=t3.medium \
--node-size=t3.medium \
--zones=ap-south-1a,ap-south-1b \
--name=${KOPS_CLUSTER_NAME} \
--dns private \
--master-count 1

root@ip-172-31-20-73:/home/ubuntu# kops create cluster --cloud=aws --zones=ap-southeast-1a --name=dev.k8s.tnhdevops.lk --dns-zone=tnhdevops.lk --dns private --networking flannel
I0808 12:27:42.219443    2161 new_cluster.go:1011]  Cloud Provider ID = aws
I0808 12:27:42.296195    2161 subnets.go:180] Assigned CIDR 172.20.32.0/19 to subnet ap-southeast-1a
I0808 12:27:42.805624    2161 create_cluster.go:728] Using SSH public key: /root/.ssh/id_rsa.pub
Previewing changes that will be made:

I0808 12:27:46.235180    2161 dns.go:97] Private DNS: skipping DNS validation
I0808 12:27:47.295486    2161 executor.go:111] Tasks: 0 done / 80 total; 43 can run
W0808 12:27:47.387188    2161 vfs_castore.go:612] CA private key was not found
I0808 12:27:48.220536    2161 executor.go:111] Tasks: 43 done / 80 total; 17 can run
I0808 12:27:49.692378    2161 executor.go:111] Tasks: 60 done / 80 total; 18 can run
I0808 12:27:49.946929    2161 executor.go:111] Tasks: 78 done / 80 total; 2 can run
I0808 12:27:50.043878    2161 executor.go:111] Tasks: 80 done / 80 total; 0 can run
Will create resources:
  AutoscalingGroup/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        Granularity             1Minute
        InstanceProtection      false
        LaunchTemplate          name:master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        LoadBalancers           []
        MaxSize                 1
        Metrics                 [GroupDesiredCapacity, GroupInServiceInstances, GroupMaxSize, GroupMinSize, GroupPendingInstances, GroupStandbyInstances, GroupTerminatingInstances, GroupTotalInstances]
        MinSize                 1
        Subnets                 [name:ap-southeast-1a.dev.k8s.tnhdevops.lk]
        SuspendProcesses        []
        Tags                    {k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/master: , k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/control-plane: , k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/kops-controller-pki: , k8s.io/role/master: 1, KubernetesCluster: dev.k8s.tnhdevops.lk, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: master-ap-southeast-1a, k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: master, k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/exclude-from-external-load-balancers: , kops.k8s.io/instancegroup: master-ap-southeast-1a, Name: master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        TargetGroups            []

  AutoscalingGroup/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        Granularity             1Minute
        InstanceProtection      false
        LaunchTemplate          name:nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        LoadBalancers           []
        MaxSize                 1
        Metrics                 [GroupDesiredCapacity, GroupInServiceInstances, GroupMaxSize, GroupMinSize, GroupPendingInstances, GroupStandbyInstances, GroupTerminatingInstances, GroupTotalInstances]
        MinSize                 1
        Subnets                 [name:ap-southeast-1a.dev.k8s.tnhdevops.lk]
        SuspendProcesses        []
        Tags                    {k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/node: , k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: node, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: nodes-ap-southeast-1a, k8s.io/role/node: 1, kops.k8s.io/instancegroup: nodes-ap-southeast-1a, Name: nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        TargetGroups            []

  DHCPOptions/dev.k8s.tnhdevops.lk
        DomainName              ap-southeast-1.compute.internal
        DomainNameServers       AmazonProvidedDNS
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  EBSVolume/a.etcd-events.dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        Encrypted               true
        SizeGB                  20
        Tags                    {k8s.io/etcd/events: a/a, k8s.io/role/master: 1, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: a.etcd-events.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}
        VolumeIops              3000
        VolumeThroughput        125
        VolumeType              gp3

  EBSVolume/a.etcd-main.dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        Encrypted               true
        SizeGB                  20
        Tags                    {k8s.io/etcd/main: a/a, k8s.io/role/master: 1, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: a.etcd-main.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}
        VolumeIops              3000
        VolumeThroughput        125
        VolumeType              gp3

  IAMInstanceProfile/masters.dev.k8s.tnhdevops.lk
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        Shared                  false

  IAMInstanceProfile/nodes.dev.k8s.tnhdevops.lk
        Tags                    {Name: nodes.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        Shared                  false

  IAMInstanceProfileRole/masters.dev.k8s.tnhdevops.lk
        InstanceProfile         name:masters.dev.k8s.tnhdevops.lk id:masters.dev.k8s.tnhdevops.lk
        Role                    name:masters.dev.k8s.tnhdevops.lk

  IAMInstanceProfileRole/nodes.dev.k8s.tnhdevops.lk
        InstanceProfile         name:nodes.dev.k8s.tnhdevops.lk id:nodes.dev.k8s.tnhdevops.lk
        Role                    name:nodes.dev.k8s.tnhdevops.lk

  IAMRole/masters.dev.k8s.tnhdevops.lk
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        ExportWithID            masters

  IAMRole/nodes.dev.k8s.tnhdevops.lk
        Tags                    {Name: nodes.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        ExportWithID            nodes

  IAMRolePolicy/master-policyoverride
        Role                    name:masters.dev.k8s.tnhdevops.lk
        Managed                 true

  IAMRolePolicy/masters.dev.k8s.tnhdevops.lk
        Role                    name:masters.dev.k8s.tnhdevops.lk
        Managed                 false

  IAMRolePolicy/node-policyoverride
        Role                    name:nodes.dev.k8s.tnhdevops.lk
        Managed                 true

  IAMRolePolicy/nodes.dev.k8s.tnhdevops.lk
        Role                    name:nodes.dev.k8s.tnhdevops.lk
        Managed                 false

  InternetGateway/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        Shared                  false
        Tags                    {kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}

  Keypair/apiserver-aggregator-ca
        Subject                 cn=apiserver-aggregator-ca
        Type                    ca
        LegacyFormat            false

  Keypair/ca
        Subject                 cn=kubernetes
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-clients-ca
        Subject                 cn=etcd-clients-ca
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-manager-ca-events
        Subject                 cn=etcd-manager-ca-events
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-manager-ca-main
        Subject                 cn=etcd-manager-ca-main
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-peers-ca-events
        Subject                 cn=etcd-peers-ca-events
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-peers-ca-main
        Subject                 cn=etcd-peers-ca-main
        Type                    ca
        LegacyFormat            false

  Keypair/service-account
        Subject                 cn=service-account
        Type                    ca
        LegacyFormat            false

  LaunchTemplate/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        AssociatePublicIP       true
        CPUCredits
        HTTPPutResponseHopLimit 1
        HTTPTokens              optional
        IAMInstanceProfile      name:masters.dev.k8s.tnhdevops.lk id:masters.dev.k8s.tnhdevops.lk
        ImageID                 099720109477/ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20210720
        InstanceMonitoring      false
        InstanceType            t3.medium
        RootVolumeIops          3000
        RootVolumeSize          64
        RootVolumeThroughput    125
        RootVolumeType          gp3
        RootVolumeEncryption    true
        RootVolumeKmsKey
        SSHKey                  name:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93 id:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        SecurityGroups          [name:masters.dev.k8s.tnhdevops.lk]
        SpotPrice
        Tags                    {kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: master-ap-southeast-1a, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/kops-controller-pki: , k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/exclude-from-external-load-balancers: , k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/master: , k8s.io/role/master: 1, kops.k8s.io/instancegroup: master-ap-southeast-1a, Name: master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk, k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: master, k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/control-plane: , KubernetesCluster: dev.k8s.tnhdevops.lk}

  LaunchTemplate/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        AssociatePublicIP       true
        CPUCredits
        HTTPPutResponseHopLimit 1
        HTTPTokens              optional
        IAMInstanceProfile      name:nodes.dev.k8s.tnhdevops.lk id:nodes.dev.k8s.tnhdevops.lk
        ImageID                 099720109477/ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20210720
        InstanceMonitoring      false
        InstanceType            t3.medium
        RootVolumeIops          3000
        RootVolumeSize          128
        RootVolumeThroughput    125
        RootVolumeType          gp3
        RootVolumeEncryption    true
        RootVolumeKmsKey
        SSHKey                  name:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93 id:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        SecurityGroups          [name:nodes.dev.k8s.tnhdevops.lk]
        SpotPrice
        Tags                    {kops.k8s.io/instancegroup: nodes-ap-southeast-1a, Name: nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/node: , k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: node, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: nodes-ap-southeast-1a, k8s.io/role/node: 1}

  ManagedFile/dev.k8s.tnhdevops.lk-addons-bootstrap
        Location                addons/bootstrap-channel.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-core.addons.k8s.io
        Location                addons/core.addons.k8s.io/v1.4.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-coredns.addons.k8s.io-k8s-1.12
        Location                addons/coredns.addons.k8s.io/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-dns-controller.addons.k8s.io-k8s-1.12
        Location                addons/dns-controller.addons.k8s.io/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-kops-controller.addons.k8s.io-k8s-1.16
        Location                addons/kops-controller.addons.k8s.io/k8s-1.16.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-kubelet-api.rbac.addons.k8s.io-k8s-1.9
        Location                addons/kubelet-api.rbac.addons.k8s.io/k8s-1.9.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-limit-range.addons.k8s.io
        Location                addons/limit-range.addons.k8s.io/v1.5.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-networking.flannel-k8s-1.12
        Location                addons/networking.flannel/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-storage-aws.addons.k8s.io-v1.15.0
        Location                addons/storage-aws.addons.k8s.io/v1.15.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-storage-aws.addons.k8s.io-v1.7.0
        Location                addons/storage-aws.addons.k8s.io/v1.7.0.yaml

  ManagedFile/etcd-cluster-spec-events
        Base                    s3://dev.k8s.tnhdevops.lk/dev.k8s.tnhdevops.lk/backups/etcd/events
        Location                /control/etcd-cluster-spec

  ManagedFile/etcd-cluster-spec-main
        Base                    s3://dev.k8s.tnhdevops.lk/dev.k8s.tnhdevops.lk/backups/etcd/main
        Location                /control/etcd-cluster-spec

  ManagedFile/manifests-etcdmanager-events
        Location                manifests/etcd/events.yaml

  ManagedFile/manifests-etcdmanager-main
        Location                manifests/etcd/main.yaml

  ManagedFile/manifests-static-kube-apiserver-healthcheck
        Location                manifests/static/kube-apiserver-healthcheck.yaml

  Route/0.0.0.0/0
        RouteTable              name:dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        InternetGateway         name:dev.k8s.tnhdevops.lk

  RouteTable/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, kubernetes.io/kops/role: public}

  RouteTableAssociation/ap-southeast-1a.dev.k8s.tnhdevops.lk
        RouteTable              name:dev.k8s.tnhdevops.lk
        Subnet                  name:ap-southeast-1a.dev.k8s.tnhdevops.lk

  SSHKey/kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        Shared                  false
        KeyFingerprint          31:5c:37:48:72:a3:30:b9:42:d2:4a:f5:3c:04:95:d8
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  Secret/admin

  Secret/kube

  Secret/kube-proxy

  Secret/kubelet

  Secret/system:controller_manager

  Secret/system:dns

  Secret/system:logging

  Secret/system:monitoring

  Secret/system:scheduler

  SecurityGroup/masters.dev.k8s.tnhdevops.lk
        Description             Security group for masters
        VPC                     name:dev.k8s.tnhdevops.lk
        RemoveExtraRules        [port=22, port=443, port=2380, port=2381, port=4001, port=4002, port=4789, port=179, port=8443]
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  SecurityGroup/nodes.dev.k8s.tnhdevops.lk
        Description             Security group for nodes
        VPC                     name:dev.k8s.tnhdevops.lk
        RemoveExtraRules        [port=22]
        Tags                    {KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: nodes.dev.k8s.tnhdevops.lk}

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-22to22-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                22
        ToPort                  22

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-22to22-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                22
        ToPort                  22

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-443to443-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                443
        ToPort                  443

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-egress-all-0to0-0.0.0.0/0
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Egress                  true

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-ingress-all-0to0-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        SourceGroup             name:masters.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-ingress-all-0to0-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        SourceGroup             name:masters.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-egress-all-0to0-0.0.0.0/0
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Egress                  true

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-all-0to0-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-1to2379-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                1
        ToPort                  2379
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-2382to4000-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                2382
        ToPort                  4000
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-4003to65535-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                4003
        ToPort                  65535
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-udp-1to65535-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                udp
        FromPort                1
        ToPort                  65535
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  Subnet/ap-southeast-1a.dev.k8s.tnhdevops.lk
        ShortName               ap-southeast-1a
        VPC                     name:dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        CIDR                    172.20.32.0/19
        Shared                  false
        Tags                    {SubnetType: Public, kubernetes.io/role/elb: 1, kubernetes.io/role/internal-elb: 1, Name: ap-southeast-1a.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  VPC/dev.k8s.tnhdevops.lk
        CIDR                    172.20.0.0/16
        EnableDNSHostnames      true
        EnableDNSSupport        true
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  VPCDHCPOptionsAssociation/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        DHCPOptions             name:dev.k8s.tnhdevops.lk

  WarmPool/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        Enabled                 false
        MinSize                 0

  WarmPool/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        Enabled                 false
        MinSize                 0

Will modify resources:
  DNSZone/tnhdevops.lk
        PrivateVPC               <nil> -> name:dev.k8s.tnhdevops.lk

Must specify --yes to apply changes

Cluster configuration has been created.

Suggestions:
 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster dev.k8s.tnhdevops.lk
 * edit your node instance group: kops edit ig --name=dev.k8s.tnhdevops.lk nodes-ap-southeast-1a
 * edit your master instance group: kops edit ig --name=dev.k8s.tnhdevops.lk master-ap-southeast-1a

Finally configure your cluster with: kops update cluster --name dev.k8s.tnhdevops.lk --yes --admin



Step 13
=======

root@ip-172-31-20-73:/home/ubuntu# kops get cluster
NAME                    CLOUD   ZONES
dev.k8s.tnhdevops.lk    aws     ap-southeast-1a

now the Defintions are stored in the S3 bucket , Lets take those and create the cluster

first if u want to see the actvities try below command


root@ip-172-31-20-73:/home/ubuntu# kops update cluster --name dev.k8s.tnhdevops.lk
I0808 12:31:56.823084    2179 dns.go:97] Private DNS: skipping DNS validation
I0808 12:31:58.662632    2179 executor.go:111] Tasks: 0 done / 80 total; 43 can run
W0808 12:31:58.740658    2179 vfs_castore.go:612] CA private key was not found
I0808 12:31:59.559991    2179 executor.go:111] Tasks: 43 done / 80 total; 17 can run
I0808 12:32:01.097993    2179 executor.go:111] Tasks: 60 done / 80 total; 18 can run
I0808 12:32:01.354894    2179 executor.go:111] Tasks: 78 done / 80 total; 2 can run
I0808 12:32:01.458363    2179 executor.go:111] Tasks: 80 done / 80 total; 0 can run
Will create resources:
  AutoscalingGroup/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        Granularity             1Minute
        InstanceProtection      false
        LaunchTemplate          name:master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        LoadBalancers           []
        MaxSize                 1
        Metrics                 [GroupDesiredCapacity, GroupInServiceInstances, GroupMaxSize, GroupMinSize, GroupPendingInstances, GroupStandbyInstances, GroupTerminatingInstances, GroupTotalInstances]
        MinSize                 1
        Subnets                 [name:ap-southeast-1a.dev.k8s.tnhdevops.lk]
        SuspendProcesses        []
        Tags                    {k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/kops-controller-pki: , k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: master-ap-southeast-1a, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/master: , k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/control-plane: , k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: master, k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/exclude-from-external-load-balancers: , k8s.io/role/master: 1, Name: master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk, kops.k8s.io/instancegroup: master-ap-southeast-1a}
        TargetGroups            []

  AutoscalingGroup/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        Granularity             1Minute
        InstanceProtection      false
        LaunchTemplate          name:nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        LoadBalancers           []
        MaxSize                 1
        Metrics                 [GroupDesiredCapacity, GroupInServiceInstances, GroupMaxSize, GroupMinSize, GroupPendingInstances, GroupStandbyInstances, GroupTerminatingInstances, GroupTotalInstances]
        MinSize                 1
        Subnets                 [name:ap-southeast-1a.dev.k8s.tnhdevops.lk]
        SuspendProcesses        []
        Tags                    {Name: nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: node, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: nodes-ap-southeast-1a, k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/node: , k8s.io/role/node: 1, kops.k8s.io/instancegroup: nodes-ap-southeast-1a}
        TargetGroups            []

  DHCPOptions/dev.k8s.tnhdevops.lk
        DomainName              ap-southeast-1.compute.internal
        DomainNameServers       AmazonProvidedDNS
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  EBSVolume/a.etcd-events.dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        Encrypted               true
        SizeGB                  20
        Tags                    {k8s.io/role/master: 1, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: a.etcd-events.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, k8s.io/etcd/events: a/a}
        VolumeIops              3000
        VolumeThroughput        125
        VolumeType              gp3

  EBSVolume/a.etcd-main.dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        Encrypted               true
        SizeGB                  20
        Tags                    {k8s.io/etcd/main: a/a, k8s.io/role/master: 1, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: a.etcd-main.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}
        VolumeIops              3000
        VolumeThroughput        125
        VolumeType              gp3

  IAMInstanceProfile/masters.dev.k8s.tnhdevops.lk
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        Shared                  false

  IAMInstanceProfile/nodes.dev.k8s.tnhdevops.lk
        Tags                    {kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, Name: nodes.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}
        Shared                  false

  IAMInstanceProfileRole/masters.dev.k8s.tnhdevops.lk
        InstanceProfile         name:masters.dev.k8s.tnhdevops.lk id:masters.dev.k8s.tnhdevops.lk
        Role                    name:masters.dev.k8s.tnhdevops.lk

  IAMInstanceProfileRole/nodes.dev.k8s.tnhdevops.lk
        InstanceProfile         name:nodes.dev.k8s.tnhdevops.lk id:nodes.dev.k8s.tnhdevops.lk
        Role                    name:nodes.dev.k8s.tnhdevops.lk

  IAMRole/masters.dev.k8s.tnhdevops.lk
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        ExportWithID            masters

  IAMRole/nodes.dev.k8s.tnhdevops.lk
        Tags                    {Name: nodes.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}
        ExportWithID            nodes

  IAMRolePolicy/master-policyoverride
        Role                    name:masters.dev.k8s.tnhdevops.lk
        Managed                 true

  IAMRolePolicy/masters.dev.k8s.tnhdevops.lk
        Role                    name:masters.dev.k8s.tnhdevops.lk
        Managed                 false

  IAMRolePolicy/node-policyoverride
        Role                    name:nodes.dev.k8s.tnhdevops.lk
        Managed                 true

  IAMRolePolicy/nodes.dev.k8s.tnhdevops.lk
        Role                    name:nodes.dev.k8s.tnhdevops.lk
        Managed                 false

  InternetGateway/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  Keypair/apiserver-aggregator-ca
        Subject                 cn=apiserver-aggregator-ca
        Type                    ca
        LegacyFormat            false

  Keypair/ca
        Subject                 cn=kubernetes
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-clients-ca
        Subject                 cn=etcd-clients-ca
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-manager-ca-events
        Subject                 cn=etcd-manager-ca-events
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-manager-ca-main
        Subject                 cn=etcd-manager-ca-main
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-peers-ca-events
        Subject                 cn=etcd-peers-ca-events
        Type                    ca
        LegacyFormat            false

  Keypair/etcd-peers-ca-main
        Subject                 cn=etcd-peers-ca-main
        Type                    ca
        LegacyFormat            false

  Keypair/service-account
        Subject                 cn=service-account
        Type                    ca
        LegacyFormat            false

  LaunchTemplate/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        AssociatePublicIP       true
        CPUCredits
        HTTPPutResponseHopLimit 1
        HTTPTokens              optional
        IAMInstanceProfile      name:masters.dev.k8s.tnhdevops.lk id:masters.dev.k8s.tnhdevops.lk
        ImageID                 099720109477/ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20210720
        InstanceMonitoring      false
        InstanceType            t3.medium
        RootVolumeIops          3000
        RootVolumeSize          64
        RootVolumeThroughput    125
        RootVolumeType          gp3
        RootVolumeEncryption    true
        RootVolumeKmsKey
        SSHKey                  name:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93 id:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        SecurityGroups          [name:masters.dev.k8s.tnhdevops.lk]
        SpotPrice
        Tags                    {k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/control-plane: , k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: master-ap-southeast-1a, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/kops-controller-pki: , k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/master: , Name: master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: master, k8s.io/cluster-autoscaler/node-template/label/node.kubernetes.io/exclude-from-external-load-balancers: , k8s.io/role/master: 1, kops.k8s.io/instancegroup: master-ap-southeast-1a, KubernetesCluster: dev.k8s.tnhdevops.lk}

  LaunchTemplate/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        AssociatePublicIP       true
        CPUCredits
        HTTPPutResponseHopLimit 1
        HTTPTokens              optional
        IAMInstanceProfile      name:nodes.dev.k8s.tnhdevops.lk id:nodes.dev.k8s.tnhdevops.lk
        ImageID                 099720109477/ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20210720
        InstanceMonitoring      false
        InstanceType            t3.medium
        RootVolumeIops          3000
        RootVolumeSize          128
        RootVolumeThroughput    125
        RootVolumeType          gp3
        RootVolumeEncryption    true
        RootVolumeKmsKey
        SSHKey                  name:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93 id:kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        SecurityGroups          [name:nodes.dev.k8s.tnhdevops.lk]
        SpotPrice
        Tags                    {KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, k8s.io/cluster-autoscaler/node-template/label/node-role.kubernetes.io/node: , k8s.io/cluster-autoscaler/node-template/label/kubernetes.io/role: node, k8s.io/cluster-autoscaler/node-template/label/kops.k8s.io/instancegroup: nodes-ap-southeast-1a, k8s.io/role/node: 1, kops.k8s.io/instancegroup: nodes-ap-southeast-1a, Name: nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk}

  ManagedFile/dev.k8s.tnhdevops.lk-addons-bootstrap
        Location                addons/bootstrap-channel.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-core.addons.k8s.io
        Location                addons/core.addons.k8s.io/v1.4.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-coredns.addons.k8s.io-k8s-1.12
        Location                addons/coredns.addons.k8s.io/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-dns-controller.addons.k8s.io-k8s-1.12
        Location                addons/dns-controller.addons.k8s.io/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-kops-controller.addons.k8s.io-k8s-1.16
        Location                addons/kops-controller.addons.k8s.io/k8s-1.16.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-kubelet-api.rbac.addons.k8s.io-k8s-1.9
        Location                addons/kubelet-api.rbac.addons.k8s.io/k8s-1.9.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-limit-range.addons.k8s.io
        Location                addons/limit-range.addons.k8s.io/v1.5.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-networking.flannel-k8s-1.12
        Location                addons/networking.flannel/k8s-1.12.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-storage-aws.addons.k8s.io-v1.15.0
        Location                addons/storage-aws.addons.k8s.io/v1.15.0.yaml

  ManagedFile/dev.k8s.tnhdevops.lk-addons-storage-aws.addons.k8s.io-v1.7.0
        Location                addons/storage-aws.addons.k8s.io/v1.7.0.yaml

  ManagedFile/etcd-cluster-spec-events
        Base                    s3://dev.k8s.tnhdevops.lk/dev.k8s.tnhdevops.lk/backups/etcd/events
        Location                /control/etcd-cluster-spec

  ManagedFile/etcd-cluster-spec-main
        Base                    s3://dev.k8s.tnhdevops.lk/dev.k8s.tnhdevops.lk/backups/etcd/main
        Location                /control/etcd-cluster-spec

  ManagedFile/manifests-etcdmanager-events
        Location                manifests/etcd/events.yaml

  ManagedFile/manifests-etcdmanager-main
        Location                manifests/etcd/main.yaml

  ManagedFile/manifests-static-kube-apiserver-healthcheck
        Location                manifests/static/kube-apiserver-healthcheck.yaml

  Route/0.0.0.0/0
        RouteTable              name:dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        InternetGateway         name:dev.k8s.tnhdevops.lk

  RouteTable/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        Shared                  false
        Tags                    {kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, kubernetes.io/kops/role: public, Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}

  RouteTableAssociation/ap-southeast-1a.dev.k8s.tnhdevops.lk
        RouteTable              name:dev.k8s.tnhdevops.lk
        Subnet                  name:ap-southeast-1a.dev.k8s.tnhdevops.lk

  SSHKey/kubernetes.dev.k8s.tnhdevops.lk-1e:b2:8d:46:37:40:44:a6:ee:ed:2e:82:4b:da:78:93
        Shared                  false
        KeyFingerprint          31:5c:37:48:72:a3:30:b9:42:d2:4a:f5:3c:04:95:d8
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  Secret/admin

  Secret/kube

  Secret/kube-proxy

  Secret/kubelet

  Secret/system:controller_manager

  Secret/system:dns

  Secret/system:logging

  Secret/system:monitoring

  Secret/system:scheduler

  SecurityGroup/masters.dev.k8s.tnhdevops.lk
        Description             Security group for masters
        VPC                     name:dev.k8s.tnhdevops.lk
        RemoveExtraRules        [port=22, port=443, port=2380, port=2381, port=4001, port=4002, port=4789, port=179, port=8443]
        Tags                    {Name: masters.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  SecurityGroup/nodes.dev.k8s.tnhdevops.lk
        Description             Security group for nodes
        VPC                     name:dev.k8s.tnhdevops.lk
        RemoveExtraRules        [port=22]
        Tags                    {Name: nodes.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-22to22-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                22
        ToPort                  22

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-22to22-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                22
        ToPort                  22

  SecurityGroupRule/from-0.0.0.0/0-ingress-tcp-443to443-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Protocol                tcp
        FromPort                443
        ToPort                  443

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-egress-all-0to0-0.0.0.0/0
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Egress                  true

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-ingress-all-0to0-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        SourceGroup             name:masters.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-masters.dev.k8s.tnhdevops.lk-ingress-all-0to0-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        SourceGroup             name:masters.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-egress-all-0to0-0.0.0.0/0
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        CIDR                    0.0.0.0/0
        Egress                  true

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-all-0to0-nodes.dev.k8s.tnhdevops.lk
        SecurityGroup           name:nodes.dev.k8s.tnhdevops.lk
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-1to2379-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                1
        ToPort                  2379
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-2382to4000-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                2382
        ToPort                  4000
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-tcp-4003to65535-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                tcp
        FromPort                4003
        ToPort                  65535
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  SecurityGroupRule/from-nodes.dev.k8s.tnhdevops.lk-ingress-udp-1to65535-masters.dev.k8s.tnhdevops.lk
        SecurityGroup           name:masters.dev.k8s.tnhdevops.lk
        Protocol                udp
        FromPort                1
        ToPort                  65535
        SourceGroup             name:nodes.dev.k8s.tnhdevops.lk

  Subnet/ap-southeast-1a.dev.k8s.tnhdevops.lk
        ShortName               ap-southeast-1a
        VPC                     name:dev.k8s.tnhdevops.lk
        AvailabilityZone        ap-southeast-1a
        CIDR                    172.20.32.0/19
        Shared                  false
        Tags                    {kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned, SubnetType: Public, kubernetes.io/role/elb: 1, kubernetes.io/role/internal-elb: 1, Name: ap-southeast-1a.dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk}

  VPC/dev.k8s.tnhdevops.lk
        CIDR                    172.20.0.0/16
        EnableDNSHostnames      true
        EnableDNSSupport        true
        Shared                  false
        Tags                    {Name: dev.k8s.tnhdevops.lk, KubernetesCluster: dev.k8s.tnhdevops.lk, kubernetes.io/cluster/dev.k8s.tnhdevops.lk: owned}

  VPCDHCPOptionsAssociation/dev.k8s.tnhdevops.lk
        VPC                     name:dev.k8s.tnhdevops.lk
        DHCPOptions             name:dev.k8s.tnhdevops.lk

  WarmPool/master-ap-southeast-1a.masters.dev.k8s.tnhdevops.lk
        Enabled                 false
        MinSize                 0

  WarmPool/nodes-ap-southeast-1a.dev.k8s.tnhdevops.lk
        Enabled                 false
        MinSize                 0

Will modify resources:
  DNSZone/tnhdevops.lk
        PrivateVPC               <nil> -> name:dev.k8s.tnhdevops.lk

Must specify --yes to apply changes



=========================================================================
=========================================================================
Step 14
=======

to create the cluster give below command

root@ip-172-31-19-141:~# kops update cluster dev.k8s.tnhdevops.lk --yes
I0928 05:03:52.485111    2253 dns.go:95] Private DNS: skipping DNS validation
I0928 05:03:52.741559    2253 executor.go:103] Tasks: 0 done / 87 total; 42 can run
I0928 05:03:53.386257    2253 vfs_castore.go:590] Issuing new certificate: "ca"
I0928 05:03:54.818592    2253 vfs_castore.go:590] Issuing new certificate: "etcd-clients-ca"
I0928 05:03:54.837875    2253 vfs_castore.go:590] Issuing new certificate: "etcd-manager-ca-events"
I0928 05:03:55.047103    2253 vfs_castore.go:590] Issuing new certificate: "etcd-manager-ca-main"
I0928 05:03:55.141927    2253 vfs_castore.go:590] Issuing new certificate: "etcd-peers-ca-main"
I0928 05:03:55.209425    2253 vfs_castore.go:590] Issuing new certificate: "etcd-peers-ca-events"
I0928 05:03:55.368833    2253 vfs_castore.go:590] Issuing new certificate: "apiserver-aggregator-ca"
I0928 05:03:55.510705    2253 executor.go:103] Tasks: 42 done / 87 total; 25 can run
I0928 05:03:56.128625    2253 vfs_castore.go:590] Issuing new certificate: "kube-scheduler"
I0928 05:03:56.491790    2253 vfs_castore.go:590] Issuing new certificate: "kube-proxy"
I0928 05:03:56.921859    2253 vfs_castore.go:590] Issuing new certificate: "kops"
I0928 05:03:57.237146    2253 vfs_castore.go:590] Issuing new certificate: "kubelet"
I0928 05:03:57.449271    2253 vfs_castore.go:590] Issuing new certificate: "apiserver-aggregator"
I0928 05:03:57.546923    2253 vfs_castore.go:590] Issuing new certificate: "kube-controller-manager"
I0928 05:03:57.571327    2253 vfs_castore.go:590] Issuing new certificate: "apiserver-proxy-client"
I0928 05:03:57.990479    2253 vfs_castore.go:590] Issuing new certificate: "kubecfg"
I0928 05:03:58.014694    2253 vfs_castore.go:590] Issuing new certificate: "kubelet-api"
I0928 05:03:58.108169    2253 vfs_castore.go:590] Issuing new certificate: "master"
I0928 05:03:58.272638    2253 executor.go:103] Tasks: 67 done / 87 total; 18 can run
I0928 05:03:58.467729    2253 launchconfiguration.go:378] waiting for IAM instance profile "nodes.dev.k8s.tnhdevops.lk" to be ready
I0928 05:03:58.485720    2253 launchconfiguration.go:378] waiting for IAM instance profile "masters.dev.k8s.tnhdevops.lk" to be ready
I0928 05:04:08.836401    2253 executor.go:103] Tasks: 85 done / 87 total; 2 can run
I0928 05:04:09.358651    2253 executor.go:103] Tasks: 87 done / 87 total; 0 can run
I0928 05:04:09.358842    2253 dns.go:156] Pre-creating DNS records
I0928 05:04:10.059614    2253 update_cluster.go:308] Exporting kubecfg for cluster
W0928 05:04:10.123496    2253 create_kubecfg.go:77] Did not find API endpoint for gossip hostname; may not be able to reach cluster
kops has set your kubectl context to dev.k8s.tnhdevops.lk

Cluster is starting.  It should be ready in a few minutes.

Suggestions:
 * validate cluster: kops validate cluster --wait 10m
 * list nodes: kubectl get nodes --show-labels
 * ssh to the master: ssh -i ~/.ssh/id_rsa ubuntu@api.dev.k8s.tnhdevops.lk
 * the ubuntu user is specific to Ubuntu. If not using Ubuntu please use the appropriate user based on your OS.
 * read about installing addons at: https://kops.sigs.k8s.io/operations/addons.


Step 15
=======
 
Check the status


root@ip-172-31-39-31:~# kops validate cluster
Using cluster from kubectl context: dev.k8s.tnhdevops.lk

Validating cluster dev.k8s.tnhdevops.lk

INSTANCE GROUPS
NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS
master-us-east-2c       Master  t3.medium       1       1       us-east-2c
nodes                   Node    t3.medium       2       2       us-east-2c

NODE STATUS
NAME    ROLE    READY

VALIDATION ERRORS
KIND    NAME            MESSAGE
dns     apiserver       Validation Failed

The dns-controller Kubernetes deployment has not updated the Kubernetes cluster's API DNS entry to the correct IP address.  The API DNS IP address is the placeholder address that kops creates: 203.0.113.123.  Please wait about 5-10 minutes for a master to start, dns-controller to launch, and DNS to propagate.  The protokube container and dns-controller deployment logs may contain more diagnostic information.  Etcd and the API DNS entries must be updated for a kops Kubernetes cluster to start.

Validation Failed

Validation failed: cluster not yet healthy
root@ip-172-31-19-141:~# kops validate cluster
Using cluster from kubectl context: dev.k8s.tnhdevops.lk

Validating cluster dev.k8s.tnhdevops.lk


INSTANCE GROUPS
NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS
master-us-east-2c       Master  t3.medium       1       1       us-east-2c
nodes                   Node    t3.medium       2       2       us-east-2c

NODE STATUS
NAME                                            ROLE    READY
ip-172-20-43-25.us-east-2.compute.internal      node    True
ip-172-20-57-165.us-east-2.compute.internal     node    True
ip-172-20-60-9.us-east-2.compute.internal       master  True

Your cluster dev.k8s.tnhdevops.lk is ready



root@ip-172-31-19-141:~# kubectl get no -o wide
NAME                                          STATUS   ROLES    AGE     VERSION   INTERNAL-IP     EXTERNAL-IP      OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME
ip-172-20-43-25.us-east-2.compute.internal    Ready    node     4m24s   v1.18.9   172.20.43.25    3.14.13.244      Ubuntu 20.04.1 LTS   5.4.0-1024-aws   docker://19.3.11
ip-172-20-57-165.us-east-2.compute.internal   Ready    node     4m32s   v1.18.9   172.20.57.165   18.223.114.192   Ubuntu 20.04.1 LTS   5.4.0-1024-aws   docker://19.3.11
ip-172-20-60-9.us-east-2.compute.internal     Ready    master   6m4s    v1.18.9   172.20.60.9     3.19.234.141     Ubuntu 20.04.1 LTS   5.4.0-1024-aws   docker://19.3.11


root@ip-172-31-19-141:~# kubectl get no
NAME                                          STATUS   ROLES    AGE     VERSION
ip-172-20-43-25.us-east-2.compute.internal    Ready    node     5m10s   v1.18.9
ip-172-20-57-165.us-east-2.compute.internal   Ready    node     5m18s   v1.18.9
ip-172-20-60-9.us-east-2.compute.internal     Ready    master   6m50s   v1.18.9
root@ip-172-31-19-141:~#

root@ip-172-31-19-141:~# kubectl get po
No resources found in default namespace.
root@ip-172-31-19-141:~#

Step 16
=======

Take look at the instances in EC2 dashboard . u will see three new
instances

connect to the master node as from the free tier instance using ssh

root@ip-172-31-19-141:~# cd .ssh/
root@ip-172-31-19-141:~/.ssh# ls
authorized_keys  id_rsa  id_rsa.pub


root@ip-172-31-19-141:~/.ssh# ssh -i id_rsa ubuntu@13.212.232.184
Welcome to Ubuntu 20.04.1 LTS (GNU/Linux 5.4.0-1024-aws x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Mon Sep 28 05:27:29 UTC 2020

  System load:  0.12              Processes:                162
  Usage of /:   6.5% of 61.98GB   Users logged in:          0
  Memory usage: 24%               IPv4 address for docker0: 172.17.0.1
  Swap usage:   0%                IPv4 address for ens5:    172.20.60.9


48 updates can be installed immediately.
20 of these updates are security updates.
To see these additional updates run: apt list --upgradable



The programs included with the Ubuntu system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by
applicable law.

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

ubuntu@ip-172-20-60-9:~$

https://kubernetes.io/docs/reference/kubectl/cheatsheet/
kubectl get pods --all-namespaces

Step 17
=======

Please get familier with the cluster and  Delete the cluster

As  this production ready cluster can't be stopped by just stopping the instances.

exit  from the master node and delete the cluster as below 

switch to root  

ubuntu@ip-172-31-19-141:~$ sudo su - 

root@ip-172-31-19-141:~$ kops delete cluster dev.k8s.tnhdevops.lk --yes

21.16 - once deleted if u want to recreate the cluster 

 it is easy .. 


root@ip-172-31-19-141:~# export KOPS_STATE_STORE=s3://dev.k8s.tnhdevops.lk

root@ip-172-31-19-141:~# kops create cluster --cloud=aws --zones=ap-southeast-1a --name=dev.k8s.tnhdevops.lk --dns-zone=tnhdevops.lk --dns private --networking flannel

root@ip-172-31-19-141:~# kops update cluster --name dev.k8s.tnhdevops.lk --yes

root@ip-172-31-19-141:~# kops validate cluster
Using cluster from kubectl context: dev.k8s.tnhdevops.lk

Validating cluster dev.k8s.tnhdevops.lk

INSTANCE GROUPS
NAME                    ROLE    MACHINETYPE     MIN     MAX     SUBNETS
master-us-east-2c       Master  t3.medium       1       1       us-east-2c
nodes                   Node    t3.medium       2       2       us-east-2c

NODE STATUS
NAME                                            ROLE    READY
ip-172-20-38-118.us-east-2.compute.internal     master  True
ip-172-20-47-230.us-east-2.compute.internal     node    True
ip-172-20-60-202.us-east-2.compute.internal     node    True

Your cluster dev.k8s.tnhdevops.lk is ready


kops export kubecfg --admin
 



